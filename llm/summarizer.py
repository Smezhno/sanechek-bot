"""LLM-based message summarization."""
from typing import List

from config import settings
from llm.client import ask_llm


SUMMARY_SYSTEM_PROMPT = """–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–µ —Å–∞–º–º–∞—Ä–∏ —Ä–∞–±–æ—á–∏—Ö –ø–µ—Ä–µ–ø–∏—Å–æ–∫.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –û–ø–∏—Å–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø—Ä–µ–¥—ã—Å—Ç–æ—Ä–∏—é –æ–±—Å—É–∂–¥–µ–Ω–∏–π
2. –î–µ—Ç–∞–ª—å–Ω–æ –∏–∑–ª–æ–∂–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã —Å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç—è–º–∏
3. –ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å –≤—Å–µ –ø—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –∏—Ö –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
4. –£–∫–∞–∑–∞—Ç—å –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ –¥–µ–¥–ª–∞–π–Ω—ã
5. –û—Ç–º–µ—Ç–∏—Ç—å –≤–∞–∂–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è
6. –í—ã–¥–µ–ª–∏—Ç—å –Ω–µ—Ä–µ—à—ë–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –æ—Ç–∫—Ä—ã—Ç—ã–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:

üìã **–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã:**
[–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º]

‚úÖ **–†–µ—à–µ–Ω–∏—è:**
[–ß—Ç–æ —Ä–µ—à–∏–ª–∏, –ø–æ—á–µ–º—É, –∫–∞–∫–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –±—ã–ª–∏]

üìå **–ó–∞–¥–∞—á–∏:**
[–ö—Ç–æ, —á—Ç–æ, –∫–æ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω —Å–¥–µ–ª–∞—Ç—å]

‚ùì **–û—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã:**
[–ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ—Ä–µ—à—ë–Ω–Ω—ã–º]

üí¨ **–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**
[–í–∞–∂–Ω—ã–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

–ü—Ä–∞–≤–∏–ª–∞:
- –ü–∏—à–∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ
- –°–æ—Ö—Ä–∞–Ω—è–π —É–ø–æ–º–∏–Ω–∞–Ω–∏—è @username
- –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É: —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, –Ω–∞–∑–≤–∞–Ω–∏—è
- –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ—è—Å–Ω–æ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –æ—Ç–º–µ—Ç—å —ç—Ç–æ

–Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π"""


async def summarize_messages(messages: List[str], max_tokens: int = 1500) -> str:
    """
    Summarize a list of chat messages using LLM.
    
    Args:
        messages: List of formatted messages ("@user: text")
        max_tokens: Maximum tokens in response
    
    Returns:
        Summary text
    """
    if not messages:
        return "–ü–µ—Ä–µ–ø–∏—Å–æ–∫ –Ω–µ –±—ã–ª–æ."
    
    # Check if any API key is configured
    if not settings.openai_api_key and not settings.yandex_gpt_api_key:
        return _fallback_summary(messages)
    
    # Combine messages
    conversation = "\n".join(messages)
    
    # Limit input length (rough estimate: 4 chars per token)
    max_input_chars = 8000  # Reduced for YandexGPT limits
    if len(conversation) > max_input_chars:
        conversation = conversation[:max_input_chars] + "\n...(—Å–æ–æ–±—â–µ–Ω–∏—è –æ–±—Ä–µ–∑–∞–Ω—ã)"
    
    try:
        summary = await ask_llm(
            question=f"–°–æ–∑–¥–∞–π —Å–∞–º–º–∞—Ä–∏ —ç—Ç–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏:\n\n{conversation}",
            system_prompt=SUMMARY_SYSTEM_PROMPT,
            max_tokens=max_tokens,
            temperature=0.3
        )
        return summary
    
    except Exception as e:
        # Fallback to simple summary on error
        return _fallback_summary(messages)


def _fallback_summary(messages: List[str]) -> str:
    """Create a simple fallback summary without LLM."""
    if not messages:
        return "–ü–µ—Ä–µ–ø–∏—Å–æ–∫ –Ω–µ –±—ã–ª–æ."
    
    if len(messages) < 5:
        return "–ü–µ—Ä–µ–ø–∏—Å–∫–∞ –±—ã–ª–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π, —Ä–µ—à–∞–ª–∏ –º–µ–ª–∫–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã."
    
    # Count unique participants
    participants = set()
    for msg in messages:
        if ":" in msg:
            username = msg.split(":")[0].strip()
            participants.add(username)
    
    participant_count = len(participants)
    message_count = len(messages)
    
    return (
        f"–í —á–∞—Ç–µ –±—ã–ª–æ {message_count} —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç {participant_count} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤. "
        f"–î–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ LLM API –∫–ª—é—á."
    )
